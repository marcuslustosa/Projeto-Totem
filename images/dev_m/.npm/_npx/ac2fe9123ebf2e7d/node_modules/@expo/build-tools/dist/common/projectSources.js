"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.downloadAndUnpackProjectFromTarGzAsync = exports.prepareProjectSourcesAsync = void 0;
const path_1 = __importDefault(require("path"));
const turtle_spawn_1 = __importDefault(require("@expo/turtle-spawn"));
const fs_extra_1 = __importDefault(require("fs-extra"));
const eas_build_job_1 = require("@expo/eas-build-job");
const downloader_1 = __importDefault(require("@expo/downloader"));
async function prepareProjectSourcesAsync(ctx) {
    if ([eas_build_job_1.ArchiveSourceType.S3, eas_build_job_1.ArchiveSourceType.GCS].includes(ctx.job.projectArchive.type)) {
        throw new Error('GCS and S3 project sources should be resolved earlier to url');
    }
    else if (ctx.job.projectArchive.type === eas_build_job_1.ArchiveSourceType.PATH) {
        await prepareProjectSourcesLocallyAsync(ctx, ctx.job.projectArchive.path); // used in eas build --local
    }
    else if (ctx.job.projectArchive.type === eas_build_job_1.ArchiveSourceType.URL) {
        await downloadAndUnpackProjectFromTarGzAsync(ctx, ctx.job.projectArchive.url);
    }
    else if (ctx.job.projectArchive.type === eas_build_job_1.ArchiveSourceType.GIT) {
        await shallowCloneRepositoryAsync(ctx, ctx.job.projectArchive.repositoryUrl, ctx.job.projectArchive.gitRef);
    }
}
exports.prepareProjectSourcesAsync = prepareProjectSourcesAsync;
async function shallowCloneRepositoryAsync(ctx, projectRepoUrl, gitRef) {
    try {
        await (0, turtle_spawn_1.default)('git', ['init'], { cwd: ctx.buildDirectory });
        await (0, turtle_spawn_1.default)('git', ['remote', 'add', 'origin', projectRepoUrl], { cwd: ctx.buildDirectory });
        await (0, turtle_spawn_1.default)('git', ['fetch', 'origin', '--depth', '1', gitRef], { cwd: ctx.buildDirectory });
        await (0, turtle_spawn_1.default)('git', ['checkout', gitRef], { cwd: ctx.buildDirectory });
    }
    catch (err) {
        const sanitizedUrl = getSanitizedGitUrl(projectRepoUrl);
        if (sanitizedUrl) {
            ctx.logger.error(`Failed to clone git repository: ${sanitizedUrl}.`);
        }
        else {
            ctx.logger.error('Failed to clone git repository.');
        }
        ctx.logger.error(err.stderr);
        throw err;
    }
}
function getSanitizedGitUrl(maybeGitUrl) {
    try {
        const url = new URL(maybeGitUrl);
        if (url.password) {
            url.password = '*******';
        }
        return url.toString();
    }
    catch (_a) {
        return null;
    }
}
async function downloadAndUnpackProjectFromTarGzAsync(ctx, projectArchiveUrl) {
    var _a;
    const projectTarball = path_1.default.join(ctx.workingdir, 'project.tar.gz');
    try {
        await (0, downloader_1.default)(projectArchiveUrl, projectTarball, { retry: 3 });
    }
    catch (err) {
        (_a = ctx.reportError) === null || _a === void 0 ? void 0 : _a.call(ctx, 'Failed to download project archive', err, {
            extras: { buildId: ctx.env.EAS_BUILD_ID },
        });
        throw err;
    }
    await unpackTarGzAsync({
        destination: ctx.buildDirectory,
        source: projectTarball,
        logger: ctx.logger,
    });
}
exports.downloadAndUnpackProjectFromTarGzAsync = downloadAndUnpackProjectFromTarGzAsync;
async function prepareProjectSourcesLocallyAsync(ctx, projectArchivePath) {
    const projectTarball = path_1.default.join(ctx.workingdir, 'project.tar.gz');
    await fs_extra_1.default.copy(projectArchivePath, projectTarball);
    await unpackTarGzAsync({
        destination: ctx.buildDirectory,
        source: projectTarball,
        logger: ctx.logger,
    });
}
async function unpackTarGzAsync({ logger, source, destination, }) {
    await (0, turtle_spawn_1.default)('tar', ['-C', destination, '--strip-components', '1', '-zxf', source], {
        logger,
    });
}
//# sourceMappingURL=projectSources.js.map